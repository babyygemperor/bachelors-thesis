\chapter{\abstractname}

This thesis presents an innovative approach to automating the annotation of mathematical identifiers in scientific papers, a traditionally laborious and costly task. The study leverages \ac{LLMs}, specifically GPT-3.5 and GPT-4 from \citet{openai2023}, and open-source alternative \ac{LLMs}. They are used to generate a dictionary of identifiers and their possible descriptions, and to associate each instance of an identifier with its appropriate definition based on the given context. 

The results are evaluated using two primary metrics: the CoNLL score \citep{pradhan2012conll} which quantifies the quality of coreference clusters, and semantic accuracy which measures the correctness of the annotations. The study reveals that GPT-4 delivers the highest performance in both metrics with a CoNLL Score of 78.08 and semantic correctness of 92.21, although it is also the most expensive. In contrast, GPT-3.5 emerges as the most cost-effective and fastest model. The open-source model StableBeluga2 \citep{StableBelugaModels, touvron2023llama, mukherjee2023orca} also shows significant potential, delivering performance almost on par with the GPT models.

The findings of this study demonstrate the potential of LLMs in automating the annotation of mathematical identifiers, thereby streamlining the process of coreference resolution and formula grounding \citep{asakura2020towards}. Our work lays the ground for future research in this domain, with potential avenues including improving semantic accuracy, expanding model selection, improving annotation coverage, reducing annotation costs, and developing more sophisticated measures of semantic accuracy.
