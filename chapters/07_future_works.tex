\chapter{Future Work}\label{chapter:future_works}

While this thesis has made significant strides in the grounding of formulae, it also opens up numerous avenues for future research and development. The following are some of the promising directions for further exploration:

\begin{enumerate}

\item \textbf{Improving Semantic Accuracy:} Although the semantic accuracy achieved in this study was high, there is still room for improvement. Future work could explore more sophisticated measures of semantic accuracy and develop methods to improve the correctness of the annotations. 

\item \textbf{Expanding Model Selection:} This study primarily focused on GPT models and a select few open-source LLMs. However, there are numerous other LLMs available that could be harnessed for this task. Future research could explore the use of other models and compare their performance.

\item \textbf{Improving Coverage:} While the coverage of annotation achieved in this study was high, it was incomplete. Future work could aim to improve the coverage, aiming to achieve 100\% annotations of the papers.

\item \textbf{Reducing Costs:} Although the automation process significantly reduced the time and cost of annotation compared to manual methods, the cost of operating some models, particularly GPT-4, was still high. Future research could explore reducing these costs, making the automation process even more cost-effective.

\item \textbf{Incorporating Feedback Mechanisms:} One potential avenue for future exploration is incorporating feedback mechanisms into the annotation process. This could allow for continuous improvement of the annotations over time.

\item \textbf{Semantic Accuracy Metric:} Calculating the semantic accuracy manually is tedious. Having a method to calculate it automatically would save further hours in evaluating the new methods for grounding formulae.

\end{enumerate}

A significant obstacle in the current research is the financial cost associated with annotation, a burden that could be better. To address this issue, our future work aims to leverage open-source \ac{LLMs} for dictionary generation, which would be "cost-free," assuming the availability of the necessary hardware. The next step would be to employ a custom-trained machine-learning model to handle the association of each occurrence of mathematical identifiers.

By integrating these components—dictionary generation via open-source \ac{LLMs} and automated association through a machine learning model—we aim to create a cost-effective, locally executable solution for formula grounding. This approach would alleviate the financial constraints and democratise access to this valuable research tool.

In conclusion, while this thesis has made significant contributions to the field of mathematical language processing, there is still much work to be done. The potential benefits of automating the annotation of mathematical identifiers are immense, and the progress made in this study is a promising step towards realising this potential. The avenues for future research outlined here provide exciting opportunities for further advancements in this field.