\chapter{Related Work}\label{chapter:related_work}

The field of Mathematical Language Processing (MLP) has been progressively evolving, focusing on the complexities of understanding, annotating, and disambiguating mathematical text. This chapter critically reviews key papers that have significantly influenced this domain, thereby contextualising our current study.

\section{Understanding Mathematical Text and Formulae}

The early work by \citet{grigore2009towards} is a foundational study in mathematical language processing. Grigore emphasised the importance of linguistic context in deciphering mathematical formulae, primarily focusing on symbolic expressions within mathematical narratives. While this work laid the groundwork, it did not delve into automation or using machine-learning models for annotation.

Building upon this, the MLP project by \citet{pagael2014mathematical} introduced a novel approach employing \ac{POS} tag-based distances to estimate the probabilities of identifier-definition relationships. This approach provided a more nuanced understanding of mathematical identifiers than traditional pattern-matching techniques. However, it still relied on manual intervention for accurate results. In contrast, our approach automates this process using LLMs, eliminating the need for manual intervention and significantly reducing the time and cost of annotation.

Most recently, \citet{meadows2022survey} supported using transformer models like GPT for formula retrieval. Meadows emphasised the role of informal mathematical text in quantitative reasoning, allowing more automated approaches. Unlike our study, Meadows' research focuses not on annotation automation but on formula retrieval.

\section{Foundational Frameworks and Automation}

The pioneering work by \citet{asakura2020towards} introduced MioGatto, a cutting-edge annotation tool that anchors or grounds mathematical formulae. This tool significantly enhanced the comprehension of STEM manuscripts by resolving the ambiguity in mathematical identifiers. However, MioGatto relied on manual annotation, which is time-consuming and resource-intensive. Our research builds upon this work by automating the annotation process in MioGatto, making it more efficient and accessible.

\citet{ding2022gpt} and \citet{schubotz2017evaluating} collectively highlight the potential of automation in data annotation. Ding specifically focuses on the role of GPT-3 in reducing annotation overheads but does not delve into the mathematical language processing aspect of it. Schubotz, on the other hand, sets the stage for automated extraction frameworks for mathematical identifier definitions but does not employ \ac{LLMs} for this purpose, nor concerns the task of annotations.

Another noteworthy contribution to Mathematical Language Processing is the work by \citet{alexeeva2020mathalign}. This study proposes a rule-based approach for extracting mathematical identifiers and linking them to their in-text descriptions. The domain-agnostic approach operates directly on PDFs, requiring only the location of the formula of interest. While their rule-based method offers a structured way to link identifiers to their descriptions, it does not employ LLMs or focus on coreference resolution among mathematical identifiers, a central theme in our research.

Their work also presents a novel evaluation dataset and the tool used to create it. Unlike our approach, which leverages the capabilities of LLMs for automating the annotation process, their method relies on rule-based algorithms. This makes their approach less flexible in handling the complexities and ambiguities often found in mathematical text. Moreover, their study does not delve into their method's cost or time effectiveness aspects that we consider in our research to evaluate the practical applicability of automated annotation methods. While both works aim to automate the process of annotating mathematical identifiers, our study extends the scope by employing LLMs and focusing on coreference resolution and semantic accuracy.


\section{The Role of LLMs and Pre-trained Frameworks}

The advent of pre-trained models like "MathBERT" \citep{peng2021mathbert} and the evaluation of GPT-3.5 \citep{he2023annollm} mark significant milestones. MathBERT is fine-tuned for decoding mathematical formulae and emphasises the importance of context. However, it is not designed for annotating mathematical identifiers, our primary focus.

The research on GPT-3.5 evaluates its efficacy as a robust annotator and questions its potential to replace traditional crowdsourced methods. While this work aligns closely with our study, it does not use metrics like CoNLL or semantic accuracy, which are central to our research, nor does it tie it to mathematical text.

\section{Summary}

The body of work reviewed here offers a comprehensive landscape of the challenges and innovations in MLP. These cornerstone studies provide invaluable insights and reveal gaps our research aims to fill. As the field evolves, our study builds upon these foundational works, introducing automation and comprehensive evaluation metrics to advance the domain of mathematical identifier annotation.
